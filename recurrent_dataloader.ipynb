{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ewenmichel/miniconda3/envs/altegrad/lib/python3.10/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from random import shuffle, choices\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from GRU_pipeline import DataHolder, paths, dicDataset, GRUModel, pad_collate\n",
    "from models import VideoGRU\n",
    "\n",
    "DH = DataHolder(**paths)\n",
    "model = GRUModel(input_dim=17) #17 for openface, 23 for opensmile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_test = DH.stratified_train_test_split(feature = 'openface', speaker = 1, none_count = 800, test_size = .15, val_size = .17)\n",
    "class_weights = train_test['class_weights']\n",
    "\n",
    "class_weights = torch.Tensor([(1 - x)**5 for x in class_weights])\n",
    "train_dataset = dicDataset(**train_test['data'])\n",
    "test_dataset = dicDataset(train_dic = train_test[\"data\"][\"test_dic\"], features = train_test[\"data\"][\"features\"], targets = train_test[\"data\"][\"targets\"], test_dic = None)\n",
    "val_dataset = dicDataset(train_dic = train_test[\"data\"][\"valid_dic\"], features = train_test[\"data\"][\"features\"], targets = train_test[\"data\"][\"targets\"], test_dic = None)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size = 200, shuffle = True, collate_fn = pad_collate)\n",
    "val_loader = DataLoader(val_dataset, batch_size = 200, shuffle = True, collate_fn = pad_collate)\n",
    "test_loader = DataLoader(test_dataset, batch_size = 200, shuffle = True, collate_fn = pad_collate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_on_val():\n",
    "    model.eval()\n",
    "    tot_loss=0.0\n",
    "    for i, batch in enumerate(val_loader):\n",
    "        features, targets = batch['features'], batch['targets']\n",
    "        with torch.no_grad():\n",
    "            pred = model(features)\n",
    "        loss = criterion(pred, targets)\n",
    "        tot_loss += loss / pred.shape[0]\n",
    "    return loss\n",
    "\n",
    "hist_train_loss = []\n",
    "hist_test_loss = []\n",
    "\n",
    "def train_one_epoch(epoch, dataloader, hist_train_loss, hist_val_loss):\n",
    "\n",
    "    model.train()\n",
    "\n",
    "    epoch_loss = 0.0\n",
    "\n",
    "    for i, batch in enumerate(dataloader):\n",
    "        features, targets = batch['features'], batch['targets']\n",
    "        pred = model(features)\n",
    "        loss = criterion(pred, targets)\n",
    "\n",
    "        epoch_loss += loss / pred.shape[0]\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    hist_train_loss = hist_train_loss + [loss]\n",
    "    val_loss = eval_on_val()\n",
    "    hist_val_loss = hist_val_loss + [val_loss]\n",
    "    if epoch % 5 == 0:\n",
    "        print(f\"Training epoch {epoch} :\")\n",
    "        print(f\"================\\nTrain loss = {loss}, Val loss = {val_loss}\")\n",
    "\n",
    "    return hist_train_loss, hist_val_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = VideoGRU(input_dim=17, hidden_dim = 128, hidden_dim2 = 128, layer_dim = 2, output_dim = 5) #17 for openface, 23 for opensmile\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.0001)\n",
    "criterion = nn.BCEWithLogitsLoss(weight = class_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.4486, 0.8604, 0.8788, 0.9204, 0.5007])\n"
     ]
    }
   ],
   "source": [
    "print(class_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 1/50 [00:01<01:12,  1.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training epoch 0 :\n",
      "================\n",
      "Train loss = 0.5005479454994202, Val loss = 0.4988129138946533\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 6/50 [00:09<01:11,  1.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training epoch 5 :\n",
      "================\n",
      "Train loss = 0.4430209994316101, Val loss = 0.43972912430763245\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 11/50 [00:17<01:03,  1.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training epoch 10 :\n",
      "================\n",
      "Train loss = 0.3020833432674408, Val loss = 0.3055807650089264\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|███▏      | 16/50 [00:25<01:00,  1.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training epoch 15 :\n",
      "================\n",
      "Train loss = 0.18960797786712646, Val loss = 0.19557060301303864\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|████▏     | 21/50 [00:34<00:48,  1.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training epoch 20 :\n",
      "================\n",
      "Train loss = 0.15105944871902466, Val loss = 0.17515550553798676\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|█████▏    | 26/50 [00:43<00:47,  1.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training epoch 25 :\n",
      "================\n",
      "Train loss = 0.15557406842708588, Val loss = 0.1680157333612442\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|██████▏   | 31/50 [00:51<00:30,  1.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training epoch 30 :\n",
      "================\n",
      "Train loss = 0.18259555101394653, Val loss = 0.1633411943912506\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|███████▏  | 36/50 [01:00<00:25,  1.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training epoch 35 :\n",
      "================\n",
      "Train loss = 0.15573866665363312, Val loss = 0.15992501378059387\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 82%|████████▏ | 41/50 [01:09<00:15,  1.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training epoch 40 :\n",
      "================\n",
      "Train loss = 0.14816325902938843, Val loss = 0.15675406157970428\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|█████████▏| 46/50 [01:16<00:05,  1.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training epoch 45 :\n",
      "================\n",
      "Train loss = 0.14862214028835297, Val loss = 0.15390491485595703\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [01:22<00:00,  1.66s/it]\n"
     ]
    }
   ],
   "source": [
    "hist_train_loss = []\n",
    "hist_val_loss = []\n",
    "\n",
    "for epoch in tqdm(range(50)):\n",
    "    curr_train_loss, curr_test_loss = hist_train_loss, hist_val_loss\n",
    "    \n",
    "    hist_train_loss, hist_val_loss = train_one_epoch(epoch, train_loader, curr_train_loss, curr_test_loss)\n",
    "\n",
    "hist_train_loss = [x.detach().numpy() for x in hist_train_loss]\n",
    "hist_val_loss = [x.detach().numpy() for x in hist_val_loss]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(hist_train_loss, label='train')\n",
    "plt.plot(hist_val_loss, label='val')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part on evaluation of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    balanced_accuracy_score,\n",
    "    f1_score,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    roc_auc_score,\n",
    "    hamming_loss,\n",
    ")\n",
    "\n",
    "def hamming_score(y_true, y_pred, normalize=True, sample_weight=None):\n",
    "    acc_list = []\n",
    "    for i in range(len(y_true)):\n",
    "        set_true = set(np.where(y_true[i])[0])\n",
    "        set_pred = set(np.where(y_pred[i])[0])\n",
    "\n",
    "        tmp_a = None\n",
    "        if len(set_true) == 0 and len(set_pred) == 0:\n",
    "            tmp_a = 1\n",
    "        else:\n",
    "            tmp_a = len(set_true.intersection(set_pred)) / float(\n",
    "                len(set_true.union(set_pred))\n",
    "            )\n",
    "        acc_list.append(tmp_a)\n",
    "\n",
    "    return np.mean(acc_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:00,  2.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "outputs: \n",
      "tensor([[0.1513, 0.0230, 0.0181, 0.0076, 0.1265],\n",
      "        [0.1544, 0.0228, 0.0182, 0.0076, 0.1278],\n",
      "        [0.2181, 0.0705, 0.0601, 0.0349, 0.1884],\n",
      "        [0.1578, 0.0275, 0.0219, 0.0099, 0.1267],\n",
      "        [0.1275, 0.0117, 0.0091, 0.0031, 0.1048],\n",
      "        [0.1327, 0.0112, 0.0081, 0.0028, 0.1008],\n",
      "        [0.2621, 0.1195, 0.0993, 0.0729, 0.2189],\n",
      "        [0.1471, 0.0234, 0.0179, 0.0081, 0.1149],\n",
      "        [0.1914, 0.0392, 0.0339, 0.0147, 0.1793],\n",
      "        [0.1223, 0.0107, 0.0078, 0.0027, 0.0979],\n",
      "        [0.1139, 0.0097, 0.0070, 0.0025, 0.0860],\n",
      "        [0.1519, 0.0218, 0.0177, 0.0072, 0.1335],\n",
      "        [0.1525, 0.0212, 0.0168, 0.0069, 0.1244],\n",
      "        [0.1196, 0.0105, 0.0076, 0.0027, 0.0924],\n",
      "        [0.1978, 0.0478, 0.0404, 0.0200, 0.1744],\n",
      "        [0.3532, 0.2435, 0.2206, 0.1899, 0.3137],\n",
      "        [0.1257, 0.0108, 0.0078, 0.0027, 0.0949],\n",
      "        [0.2343, 0.0906, 0.0736, 0.0496, 0.1906],\n",
      "        [0.1166, 0.0107, 0.0078, 0.0028, 0.0885],\n",
      "        [0.1581, 0.0227, 0.0182, 0.0076, 0.1302],\n",
      "        [0.1485, 0.0203, 0.0161, 0.0064, 0.1284],\n",
      "        [0.3841, 0.2917, 0.2758, 0.2416, 0.3523],\n",
      "        [0.2462, 0.0984, 0.0798, 0.0557, 0.2004],\n",
      "        [0.2288, 0.0687, 0.0607, 0.0328, 0.2066],\n",
      "        [0.1592, 0.0223, 0.0177, 0.0067, 0.1438],\n",
      "        [0.1778, 0.0288, 0.0234, 0.0097, 0.1562],\n",
      "        [0.1377, 0.0200, 0.0153, 0.0065, 0.1052],\n",
      "        [0.1616, 0.0273, 0.0222, 0.0096, 0.1370],\n",
      "        [0.1704, 0.0278, 0.0226, 0.0094, 0.1542],\n",
      "        [0.1896, 0.0377, 0.0319, 0.0141, 0.1760],\n",
      "        [0.1871, 0.0383, 0.0322, 0.0146, 0.1682],\n",
      "        [0.1313, 0.0130, 0.0097, 0.0035, 0.1110],\n",
      "        [0.1486, 0.0208, 0.0165, 0.0067, 0.1228],\n",
      "        [0.1503, 0.0209, 0.0155, 0.0065, 0.1096],\n",
      "        [0.1281, 0.0145, 0.0111, 0.0041, 0.1052],\n",
      "        [0.1379, 0.0153, 0.0114, 0.0043, 0.1142],\n",
      "        [0.1328, 0.0130, 0.0101, 0.0036, 0.1111],\n",
      "        [0.2745, 0.1106, 0.1014, 0.0610, 0.2598],\n",
      "        [0.1504, 0.0176, 0.0136, 0.0052, 0.1236],\n",
      "        [0.1760, 0.0330, 0.0274, 0.0119, 0.1601],\n",
      "        [0.1624, 0.0242, 0.0198, 0.0079, 0.1459],\n",
      "        [0.2067, 0.0512, 0.0445, 0.0215, 0.1911],\n",
      "        [0.1096, 0.0084, 0.0057, 0.0021, 0.0728],\n",
      "        [0.1808, 0.0356, 0.0300, 0.0132, 0.1667],\n",
      "        [0.1159, 0.0094, 0.0068, 0.0024, 0.0863],\n",
      "        [0.2377, 0.0905, 0.0723, 0.0491, 0.1915],\n",
      "        [0.1211, 0.0116, 0.0087, 0.0030, 0.1045],\n",
      "        [0.1504, 0.0268, 0.0207, 0.0095, 0.1223],\n",
      "        [0.1690, 0.0286, 0.0237, 0.0099, 0.1562],\n",
      "        [0.1757, 0.0366, 0.0299, 0.0147, 0.1436],\n",
      "        [0.2321, 0.0869, 0.0697, 0.0474, 0.1878],\n",
      "        [0.1628, 0.0253, 0.0211, 0.0085, 0.1509],\n",
      "        [0.3335, 0.2122, 0.1879, 0.1565, 0.2906],\n",
      "        [0.1595, 0.0226, 0.0181, 0.0071, 0.1416],\n",
      "        [0.1396, 0.0165, 0.0126, 0.0048, 0.1155],\n",
      "        [0.1288, 0.0139, 0.0106, 0.0040, 0.1019],\n",
      "        [0.1235, 0.0116, 0.0088, 0.0030, 0.1042],\n",
      "        [0.2516, 0.0950, 0.0747, 0.0507, 0.1964],\n",
      "        [0.1414, 0.0163, 0.0129, 0.0047, 0.1213],\n",
      "        [0.1133, 0.0110, 0.0082, 0.0029, 0.0902],\n",
      "        [0.1294, 0.0133, 0.0099, 0.0036, 0.1049],\n",
      "        [0.1651, 0.0294, 0.0240, 0.0106, 0.1423],\n",
      "        [0.1657, 0.0241, 0.0199, 0.0077, 0.1540],\n",
      "        [0.1636, 0.0228, 0.0187, 0.0071, 0.1476],\n",
      "        [0.2966, 0.1595, 0.1375, 0.1067, 0.2528],\n",
      "        [0.2231, 0.0723, 0.0614, 0.0363, 0.1922],\n",
      "        [0.3280, 0.2068, 0.1847, 0.1528, 0.2878],\n",
      "        [0.1595, 0.0266, 0.0219, 0.0090, 0.1467],\n",
      "        [0.2012, 0.0485, 0.0417, 0.0203, 0.1788],\n",
      "        [0.1665, 0.0331, 0.0265, 0.0127, 0.1339],\n",
      "        [0.1553, 0.0209, 0.0162, 0.0065, 0.1297],\n",
      "        [0.2039, 0.0478, 0.0415, 0.0198, 0.1896],\n",
      "        [0.1525, 0.0197, 0.0155, 0.0060, 0.1302],\n",
      "        [0.2096, 0.0627, 0.0524, 0.0297, 0.1772],\n",
      "        [0.1852, 0.0392, 0.0330, 0.0147, 0.1715],\n",
      "        [0.1814, 0.0383, 0.0314, 0.0147, 0.1558],\n",
      "        [0.1425, 0.0192, 0.0149, 0.0064, 0.1101],\n",
      "        [0.1496, 0.0185, 0.0146, 0.0056, 0.1312],\n",
      "        [0.1501, 0.0197, 0.0153, 0.0061, 0.1191],\n",
      "        [0.1508, 0.0216, 0.0175, 0.0070, 0.1274],\n",
      "        [0.1392, 0.0173, 0.0138, 0.0053, 0.1199],\n",
      "        [0.1326, 0.0145, 0.0114, 0.0042, 0.1153],\n",
      "        [0.1276, 0.0125, 0.0096, 0.0034, 0.1095],\n",
      "        [0.2014, 0.0453, 0.0392, 0.0181, 0.1920],\n",
      "        [0.1653, 0.0274, 0.0225, 0.0093, 0.1517],\n",
      "        [0.1166, 0.0083, 0.0059, 0.0019, 0.0890],\n",
      "        [0.3427, 0.2160, 0.2019, 0.1585, 0.3145],\n",
      "        [0.1995, 0.0537, 0.0406, 0.0244, 0.1501],\n",
      "        [0.1498, 0.0188, 0.0145, 0.0057, 0.1247],\n",
      "        [0.1349, 0.0153, 0.0118, 0.0044, 0.1155],\n",
      "        [0.1562, 0.0206, 0.0163, 0.0065, 0.1266],\n",
      "        [0.1673, 0.0296, 0.0237, 0.0105, 0.1381],\n",
      "        [0.1701, 0.0285, 0.0230, 0.0095, 0.1503],\n",
      "        [0.1536, 0.0219, 0.0176, 0.0070, 0.1370],\n",
      "        [0.1372, 0.0181, 0.0142, 0.0057, 0.1144],\n",
      "        [0.1326, 0.0141, 0.0111, 0.0041, 0.1140],\n",
      "        [0.1467, 0.0166, 0.0126, 0.0048, 0.1169],\n",
      "        [0.1137, 0.0100, 0.0073, 0.0025, 0.0897],\n",
      "        [0.1752, 0.0377, 0.0304, 0.0153, 0.1441],\n",
      "        [0.1917, 0.0493, 0.0404, 0.0218, 0.1595],\n",
      "        [0.1197, 0.0122, 0.0093, 0.0034, 0.0959],\n",
      "        [0.1360, 0.0198, 0.0148, 0.0064, 0.1060],\n",
      "        [0.1269, 0.0137, 0.0100, 0.0038, 0.0922],\n",
      "        [0.1553, 0.0227, 0.0180, 0.0075, 0.1269],\n",
      "        [0.1377, 0.0144, 0.0106, 0.0039, 0.1031],\n",
      "        [0.2788, 0.1406, 0.1197, 0.0904, 0.2362],\n",
      "        [0.1422, 0.0161, 0.0125, 0.0046, 0.1210],\n",
      "        [0.2392, 0.0676, 0.0614, 0.0301, 0.2425],\n",
      "        [0.1772, 0.0325, 0.0276, 0.0118, 0.1696],\n",
      "        [0.1737, 0.0295, 0.0247, 0.0103, 0.1617],\n",
      "        [0.1464, 0.0169, 0.0134, 0.0051, 0.1179],\n",
      "        [0.1729, 0.0276, 0.0230, 0.0093, 0.1606],\n",
      "        [0.1455, 0.0169, 0.0131, 0.0048, 0.1259],\n",
      "        [0.1792, 0.0292, 0.0246, 0.0101, 0.1646],\n",
      "        [0.1551, 0.0205, 0.0158, 0.0064, 0.1231],\n",
      "        [0.1517, 0.0202, 0.0159, 0.0062, 0.1267],\n",
      "        [0.1952, 0.0533, 0.0401, 0.0240, 0.1473],\n",
      "        [0.1203, 0.0109, 0.0079, 0.0028, 0.0891],\n",
      "        [0.1382, 0.0159, 0.0126, 0.0047, 0.1229],\n",
      "        [0.2110, 0.0528, 0.0463, 0.0217, 0.2092],\n",
      "        [0.2745, 0.1103, 0.1011, 0.0607, 0.2591],\n",
      "        [0.1898, 0.0441, 0.0361, 0.0187, 0.1542],\n",
      "        [0.1565, 0.0257, 0.0196, 0.0088, 0.1211],\n",
      "        [0.1399, 0.0196, 0.0151, 0.0064, 0.1066],\n",
      "        [0.3841, 0.2917, 0.2758, 0.2416, 0.3523],\n",
      "        [0.1580, 0.0229, 0.0187, 0.0075, 0.1430],\n",
      "        [0.1378, 0.0165, 0.0128, 0.0049, 0.1195],\n",
      "        [0.1392, 0.0167, 0.0135, 0.0052, 0.1160],\n",
      "        [0.1417, 0.0151, 0.0113, 0.0042, 0.1111],\n",
      "        [0.1897, 0.0449, 0.0368, 0.0190, 0.1558],\n",
      "        [0.1793, 0.0339, 0.0283, 0.0125, 0.1621],\n",
      "        [0.1955, 0.0464, 0.0403, 0.0195, 0.1750],\n",
      "        [0.1696, 0.0277, 0.0227, 0.0094, 0.1578],\n",
      "        [0.1392, 0.0161, 0.0126, 0.0047, 0.1206],\n",
      "        [0.1776, 0.0284, 0.0229, 0.0095, 0.1576],\n",
      "        [0.1474, 0.0236, 0.0182, 0.0081, 0.1166],\n",
      "        [0.1886, 0.0442, 0.0356, 0.0182, 0.1530],\n",
      "        [0.1481, 0.0200, 0.0159, 0.0061, 0.1362],\n",
      "        [0.1705, 0.0300, 0.0247, 0.0103, 0.1623],\n",
      "        [0.2714, 0.1299, 0.1086, 0.0804, 0.2256],\n",
      "        [0.1052, 0.0070, 0.0048, 0.0016, 0.0729],\n",
      "        [0.1611, 0.0266, 0.0215, 0.0092, 0.1377],\n",
      "        [0.3142, 0.1747, 0.1507, 0.1184, 0.2665],\n",
      "        [0.1493, 0.0231, 0.0184, 0.0077, 0.1235],\n",
      "        [0.1189, 0.0116, 0.0088, 0.0032, 0.0938],\n",
      "        [0.1411, 0.0156, 0.0119, 0.0045, 0.1161],\n",
      "        [0.1778, 0.0356, 0.0286, 0.0140, 0.1449],\n",
      "        [0.1164, 0.0095, 0.0068, 0.0023, 0.0906],\n",
      "        [0.2278, 0.0752, 0.0636, 0.0387, 0.1930],\n",
      "        [0.2442, 0.0990, 0.0814, 0.0566, 0.2006],\n",
      "        [0.1442, 0.0198, 0.0154, 0.0063, 0.1191],\n",
      "        [0.2614, 0.1205, 0.1018, 0.0741, 0.2203],\n",
      "        [0.1945, 0.0582, 0.0455, 0.0283, 0.1536],\n",
      "        [0.3654, 0.2637, 0.2416, 0.2122, 0.3257],\n",
      "        [0.1447, 0.0145, 0.0112, 0.0041, 0.1214],\n",
      "        [0.1298, 0.0131, 0.0096, 0.0036, 0.0964],\n",
      "        [0.1407, 0.0165, 0.0125, 0.0048, 0.1209],\n",
      "        [0.1326, 0.0141, 0.0107, 0.0039, 0.1106],\n",
      "        [0.1414, 0.0179, 0.0141, 0.0054, 0.1241],\n",
      "        [0.3313, 0.2096, 0.1861, 0.1549, 0.2893],\n",
      "        [0.1417, 0.0184, 0.0141, 0.0056, 0.1151],\n",
      "        [0.1613, 0.0318, 0.0253, 0.0123, 0.1314],\n",
      "        [0.1242, 0.0118, 0.0090, 0.0032, 0.1047],\n",
      "        [0.1560, 0.0197, 0.0150, 0.0058, 0.1316],\n",
      "        [0.1759, 0.0305, 0.0252, 0.0107, 0.1649],\n",
      "        [0.1673, 0.0319, 0.0253, 0.0121, 0.1337],\n",
      "        [0.1844, 0.0365, 0.0302, 0.0134, 0.1702],\n",
      "        [0.1582, 0.0197, 0.0153, 0.0058, 0.1329],\n",
      "        [0.1725, 0.0303, 0.0247, 0.0107, 0.1525],\n",
      "        [0.1381, 0.0144, 0.0110, 0.0041, 0.1113],\n",
      "        [0.1320, 0.0124, 0.0092, 0.0033, 0.1058],\n",
      "        [0.1715, 0.0281, 0.0230, 0.0096, 0.1537],\n",
      "        [0.1687, 0.0303, 0.0247, 0.0107, 0.1430],\n",
      "        [0.1420, 0.0169, 0.0131, 0.0049, 0.1225],\n",
      "        [0.1352, 0.0157, 0.0122, 0.0046, 0.1159],\n",
      "        [0.1394, 0.0172, 0.0137, 0.0051, 0.1164],\n",
      "        [0.1438, 0.0155, 0.0118, 0.0043, 0.1167],\n",
      "        [0.1582, 0.0229, 0.0184, 0.0075, 0.1372],\n",
      "        [0.2211, 0.0787, 0.0630, 0.0418, 0.1787],\n",
      "        [0.3290, 0.2080, 0.1859, 0.1545, 0.2888],\n",
      "        [0.1598, 0.0261, 0.0213, 0.0089, 0.1469],\n",
      "        [0.2168, 0.0723, 0.0566, 0.0367, 0.1715],\n",
      "        [0.1531, 0.0219, 0.0176, 0.0071, 0.1334],\n",
      "        [0.1253, 0.0106, 0.0078, 0.0026, 0.0997],\n",
      "        [0.2868, 0.1276, 0.1175, 0.0748, 0.2678],\n",
      "        [0.1674, 0.0257, 0.0209, 0.0083, 0.1557],\n",
      "        [0.1326, 0.0162, 0.0126, 0.0048, 0.1107]], grad_fn=<SigmoidBackward0>)\n",
      "fin_outputs\n",
      "[[False, False, False, False, False], [False, False, False, False, False], [False, False, False, False, False], [False, False, False, False, False], [False, False, False, False, False], [False, False, False, False, False], [False, False, False, False, False], [False, False, False, False, False], [False, False, False, False, False], [False, False, False, False, False], [False, False, False, False, False], [False, False, False, False, False], [False, False, False, False, False], [False, False, False, False, False], [False, False, False, False, False], [True, False, False, False, True], [False, False, False, False, False], [False, False, False, False, False], [False, False, False, False, False], [False, False, False, False, False], [False, False, False, False, False], [True, False, False, False, True], [False, False, False, False, False], [False, False, False, False, False], [False, False, False, False, False], [False, False, False, False, False], [False, False, False, False, False], [False, False, False, False, False], [False, False, False, False, False], [False, False, False, False, False], [False, False, False, False, False], [False, False, False, False, False], [False, False, False, False, False], [False, False, False, False, False], [False, False, False, False, False], [False, False, False, False, False], [False, False, False, False, False], [False, False, False, False, False], [False, False, False, False, False], [False, False, False, False, False], [False, False, False, False, False], [False, False, False, False, False], [False, False, False, False, False], [False, False, False, False, False], [False, False, False, False, False], [False, False, False, False, False], [False, False, False, False, False], [False, False, False, False, False], [False, False, False, False, False], [False, False, False, False, False], [False, False, False, False, False], [False, False, False, False, False], [True, False, False, False, False], [False, False, False, False, False], [False, False, False, False, False], [False, False, False, False, False], [False, False, False, False, False], [False, False, False, False, False], [False, False, False, False, False], [False, False, False, False, False], [False, False, False, False, False], [False, False, False, False, False], [False, False, False, False, False], [False, False, False, False, False], [False, False, False, False, False], [False, False, False, False, False], [True, False, False, False, False], [False, False, False, False, False], [False, False, False, False, False], [False, False, False, False, False], [False, False, False, False, False], [False, False, False, False, False], [False, False, False, False, False], [False, False, False, False, False], [False, False, False, False, False], [False, False, False, False, False], [False, False, False, False, False], [False, False, False, False, False], [False, False, False, False, False], [False, False, False, False, False], [False, False, False, False, False], [False, False, False, False, False], [False, False, False, False, False], [False, False, False, False, False], [False, False, False, False, False], [False, False, False, False, False], [True, False, False, False, True], [False, False, False, False, False], [False, False, False, False, False], [False, False, False, False, False], [False, False, False, False, False], [False, False, False, False, False], [False, False, False, False, False], [False, False, False, False, False], [False, False, False, False, False], [False, False, False, False, False], [False, False, False, False, False], [False, False, False, False, False], [False, False, False, False, False], [False, False, False, False, False], [False, False, False, False, False], [False, False, False, False, False], [False, False, False, False, False], [False, False, False, False, False], [False, False, False, False, False], [False, False, False, False, False], [False, False, False, False, False], [False, False, False, False, False], [False, False, False, False, False], [False, False, False, False, False], [False, False, False, False, False], [False, False, False, False, False], [False, False, False, False, False], [False, False, False, False, False], [False, False, False, False, False], [False, False, False, False, False], [False, False, False, False, False], [False, False, False, False, False], [False, False, False, False, False], [False, False, False, False, False], [False, False, False, False, False], [False, False, False, False, False], [False, False, False, False, False], [False, False, False, False, False], [True, False, False, False, True], [False, False, False, False, False], [False, False, False, False, False], [False, False, False, False, False], [False, False, False, False, False], [False, False, False, False, False], [False, False, False, False, False], [False, False, False, False, False], [False, False, False, False, False], [False, False, False, False, False], [False, False, False, False, False], [False, False, False, False, False], [False, False, False, False, False], [False, False, False, False, False], [False, False, False, False, False], [False, False, False, False, False], [False, False, False, False, False], [False, False, False, False, False], [True, False, False, False, False], [False, False, False, False, False], [False, False, False, False, False], [False, False, False, False, False], [False, False, False, False, False], [False, False, False, False, False], [False, False, False, False, False], [False, False, False, False, False], [False, False, False, False, False], [False, False, False, False, False], [False, False, False, False, False], [True, False, False, False, True], [False, False, False, False, False], [False, False, False, False, False], [False, False, False, False, False], [False, False, False, False, False], [False, False, False, False, False], [True, False, False, False, False], [False, False, False, False, False], [False, False, False, False, False], [False, False, False, False, False], [False, False, False, False, False], [False, False, False, False, False], [False, False, False, False, False], [False, False, False, False, False], [False, False, False, False, False], [False, False, False, False, False], [False, False, False, False, False], [False, False, False, False, False], [False, False, False, False, False], [False, False, False, False, False], [False, False, False, False, False], [False, False, False, False, False], [False, False, False, False, False], [False, False, False, False, False], [False, False, False, False, False], [False, False, False, False, False], [True, False, False, False, False], [False, False, False, False, False], [False, False, False, False, False], [False, False, False, False, False], [False, False, False, False, False], [False, False, False, False, False], [False, False, False, False, False], [False, False, False, False, False]]\n",
      "fin_targets\n",
      "[[0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 1.0], [0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [1.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 1.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0]]\n",
      "[[0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [1 0 0 0 1]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [1 0 0 0 1]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [1 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [1 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [1 0 0 0 1]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [1 0 0 0 1]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [1 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [1 0 0 0 1]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [1 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [1 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]]\n",
      "Total label for SD : 28.0, number of correct pred 1.0\n",
      "Total label for QE : 6.0, number of correct pred 0.0\n",
      "Total label for SV : 8.0, number of correct pred 0.0\n",
      "Total label for PR : 3.0, number of correct pred 0.0\n",
      "Total label for HD : 26.0, number of correct pred 1.0\n",
      "Hamming Score for VideoGRU =  0.6149732620320856\n",
      "Hamming Loss for VideoGRU =  0.0877005347593583\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "/Users/ewenmichel/miniconda3/envs/altegrad/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/ewenmichel/miniconda3/envs/altegrad/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/ewenmichel/miniconda3/envs/altegrad/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "fin_targets = []\n",
    "fin_outputs = []\n",
    "\n",
    "for j, data in tqdm(enumerate(test_loader)):\n",
    "    features, targets = data['features'], data['targets']\n",
    "\n",
    "    pred = torch.nn.Sigmoid()(model(features))\n",
    "    loss = criterion(pred, targets)\n",
    "\n",
    "    fin_targets.extend(targets.cpu().detach().numpy().tolist())\n",
    "    fin_outputs.extend((np.array(pred.cpu().detach().numpy()) >= .3).tolist())\n",
    "    if j%5 == 0:\n",
    "        print(\"outputs: \")\n",
    "        print(pred)\n",
    "        print(\"fin_outputs\")\n",
    "        print(fin_outputs)\n",
    "        print(\"fin_targets\")\n",
    "        print(fin_targets)\n",
    "    val_hamming_loss = hamming_loss(fin_targets, fin_outputs)\n",
    "    val_hamming_score = hamming_score(fin_targets, fin_outputs)\n",
    "\n",
    "    cpu_y = np.where(\n",
    "        fin_targets == False,\n",
    "        0,\n",
    "        np.where(fin_targets == True, 1, np.array(fin_targets)),\n",
    "    )\n",
    "    cpu_y_hat = np.where(\n",
    "        fin_targets == False,\n",
    "        0,\n",
    "        np.where(fin_targets == True, 1, np.array(fin_outputs)),\n",
    "    )\n",
    "    print(cpu_y_hat)\n",
    "    cpu_y = cpu_y.reshape(cpu_y_hat.shape)\n",
    "    results = {}\n",
    "    f_score_tot_none = f1_score(cpu_y, cpu_y_hat, average=None)\n",
    "    f_score_tot_micro = f1_score(cpu_y, cpu_y_hat, average=\"micro\")\n",
    "    f_score_tot_macro = f1_score(cpu_y, cpu_y_hat, average=\"macro\")\n",
    "    f_score_tot_weighted = f1_score(cpu_y, cpu_y_hat, average=\"weighted\")\n",
    "\n",
    "    class_list = DH.target_col\n",
    "\n",
    "for j, c in enumerate(class_list):\n",
    "    print(\n",
    "        f\"Total label for {c} : {np.sum(cpu_y[:, j])}, number of correct pred {np.dot(cpu_y[:, j], cpu_y_hat[:, j])}\"\n",
    "    )\n",
    "    label_y = cpu_y[:, j]\n",
    "    label_pred = cpu_y_hat[:, j]\n",
    "    rec = recall_score(label_y, label_pred)\n",
    "    prec = precision_score(label_y, label_pred)\n",
    "    acc = accuracy_score(label_y, label_pred)\n",
    "\n",
    "    try:\n",
    "        auc = roc_auc_score(label_y, label_pred)\n",
    "    except ValueError:\n",
    "        auc = 1\n",
    "\n",
    "    results[c] = {\n",
    "        \"Recall\": f\"{rec:.4f}\",\n",
    "        \"Precision\": f\"{prec:.4f}\",\n",
    "        \"Accuracy\": f\"{acc:.2f}\",\n",
    "    }\n",
    "\n",
    "print(f\"Hamming Score for {type(model).__name__} = \", val_hamming_score)\n",
    "print(f\"Hamming Loss for {type(model).__name__} = \", val_hamming_loss)\n",
    "with open(\"models/results.txt\", \"a\") as f:\n",
    "    f.write(\"=========================\\n\")\n",
    "    f.write(f\"EVALUATING {type(model).__name__}\\n\")\n",
    "    f.write(\"=========================\\n\")\n",
    "    for k_ in results.keys():\n",
    "        f.write(str(k_) + str(results[k_]) + \"\\n\")\n",
    "    f.write(\"Total f1 score : {}\\n\".format(f_score_tot_none))\n",
    "    f.write(\"Total f1 score micro : {}\\n\".format(f_score_tot_micro))\n",
    "    f.write(\"Total f1 score macro : {}\\n\".format(f_score_tot_macro))\n",
    "    f.write(\"Total f1 score weighted : {}\\n\".format(f_score_tot_weighted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2it [00:00,  5.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.0000e+00, 1.7075e-06, 1.0072e-06, 7.5992e-07, 1.0000e+00],\n",
      "        [1.0000e+00, 2.0108e-06, 1.1965e-06, 9.1384e-07, 1.0000e+00],\n",
      "        [1.0000e+00, 1.6426e-06, 9.6638e-07, 7.2778e-07, 1.0000e+00],\n",
      "        [1.0000e+00, 2.0649e-06, 1.2336e-06, 9.4719e-07, 1.0000e+00],\n",
      "        [9.9996e-01, 8.3359e-05, 5.9957e-05, 5.1650e-05, 9.9986e-01],\n",
      "        [1.0000e+00, 1.6423e-06, 9.6674e-07, 7.2603e-07, 1.0000e+00],\n",
      "        [1.0000e+00, 2.1072e-06, 1.2574e-06, 9.6372e-07, 1.0000e+00],\n",
      "        [9.9999e-01, 1.7586e-05, 1.1308e-05, 9.4599e-06, 9.9997e-01],\n",
      "        [1.0000e+00, 1.8707e-06, 1.1109e-06, 8.4767e-07, 1.0000e+00],\n",
      "        [1.0000e+00, 1.6200e-06, 9.5265e-07, 7.1497e-07, 1.0000e+00],\n",
      "        [1.0000e+00, 1.6315e-06, 9.5963e-07, 7.2150e-07, 1.0000e+00],\n",
      "        [1.0000e+00, 1.6292e-06, 9.5812e-07, 7.2013e-07, 1.0000e+00],\n",
      "        [1.0000e+00, 1.6996e-06, 1.0026e-06, 7.5803e-07, 1.0000e+00],\n",
      "        [1.0000e+00, 1.6650e-06, 9.8193e-07, 7.3872e-07, 1.0000e+00],\n",
      "        [1.0000e+00, 1.7231e-06, 1.0165e-06, 7.6842e-07, 1.0000e+00],\n",
      "        [1.0000e+00, 1.6207e-06, 9.5288e-07, 7.1561e-07, 1.0000e+00],\n",
      "        [1.0000e+00, 1.6300e-06, 9.5885e-07, 7.2065e-07, 1.0000e+00],\n",
      "        [1.0000e+00, 1.8732e-06, 1.1114e-06, 8.4799e-07, 1.0000e+00],\n",
      "        [1.0000e+00, 1.6430e-06, 9.6676e-07, 7.2795e-07, 1.0000e+00],\n",
      "        [1.0000e+00, 1.6277e-06, 9.5755e-07, 7.1928e-07, 1.0000e+00],\n",
      "        [1.0000e+00, 1.6326e-06, 9.6058e-07, 7.2084e-07, 1.0000e+00],\n",
      "        [1.0000e+00, 1.6257e-06, 9.5594e-07, 7.1847e-07, 1.0000e+00],\n",
      "        [1.0000e+00, 1.7265e-06, 1.0190e-06, 7.7004e-07, 1.0000e+00],\n",
      "        [1.0000e+00, 1.6186e-06, 9.5254e-07, 7.1374e-07, 1.0000e+00],\n",
      "        [9.9995e-01, 1.1033e-04, 7.6247e-05, 6.7999e-05, 9.9982e-01],\n",
      "        [1.0000e+00, 1.8477e-06, 1.0925e-06, 8.2859e-07, 1.0000e+00],\n",
      "        [1.0000e+00, 1.7911e-06, 1.0604e-06, 8.0556e-07, 1.0000e+00],\n",
      "        [1.0000e+00, 1.6322e-06, 9.6008e-07, 7.2205e-07, 1.0000e+00],\n",
      "        [1.0000e+00, 2.1246e-06, 1.2697e-06, 9.7366e-07, 1.0000e+00],\n",
      "        [9.9986e-01, 2.8851e-04, 2.0740e-04, 1.9045e-04, 9.9955e-01],\n",
      "        [1.0000e+00, 1.6671e-06, 9.8281e-07, 7.3931e-07, 1.0000e+00],\n",
      "        [9.9998e-01, 5.1443e-05, 3.4560e-05, 3.0067e-05, 9.9992e-01]],\n",
      "       grad_fn=<SigmoidBackward0>)\n",
      "tensor([[1.0000e+00, 1.6826e-06, 9.9114e-07, 7.4641e-07, 1.0000e+00],\n",
      "        [1.0000e+00, 1.7208e-06, 1.0159e-06, 7.6941e-07, 1.0000e+00],\n",
      "        [1.0000e+00, 1.7295e-06, 1.0220e-06, 7.7258e-07, 1.0000e+00],\n",
      "        [1.0000e+00, 1.8425e-06, 1.0941e-06, 8.3205e-07, 1.0000e+00],\n",
      "        [1.0000e+00, 1.6154e-06, 9.5016e-07, 7.1210e-07, 1.0000e+00],\n",
      "        [1.0000e+00, 1.7925e-06, 1.0619e-06, 8.0626e-07, 1.0000e+00],\n",
      "        [9.9999e-01, 1.8546e-05, 1.1931e-05, 9.9938e-06, 9.9997e-01],\n",
      "        [1.0000e+00, 1.7843e-06, 1.0523e-06, 7.9642e-07, 1.0000e+00],\n",
      "        [1.0000e+00, 1.6381e-06, 9.6394e-07, 7.2491e-07, 1.0000e+00],\n",
      "        [1.0000e+00, 1.6554e-06, 9.7440e-07, 7.3484e-07, 1.0000e+00],\n",
      "        [1.0000e+00, 1.8230e-06, 1.0802e-06, 8.2038e-07, 1.0000e+00],\n",
      "        [1.0000e+00, 1.7440e-06, 1.0299e-06, 7.7955e-07, 1.0000e+00],\n",
      "        [1.0000e+00, 3.2370e-06, 1.9873e-06, 1.5528e-06, 9.9999e-01],\n",
      "        [1.0000e+00, 1.7200e-06, 1.0157e-06, 7.6856e-07, 1.0000e+00],\n",
      "        [1.0000e+00, 1.6383e-06, 9.6399e-07, 7.2409e-07, 1.0000e+00],\n",
      "        [1.0000e+00, 1.6357e-06, 9.6288e-07, 7.2315e-07, 1.0000e+00],\n",
      "        [1.0000e+00, 1.6513e-06, 9.7256e-07, 7.3047e-07, 1.0000e+00],\n",
      "        [1.0000e+00, 5.8209e-06, 3.6954e-06, 2.9333e-06, 9.9999e-01],\n",
      "        [1.0000e+00, 2.1694e-06, 1.3001e-06, 9.9941e-07, 1.0000e+00],\n",
      "        [1.0000e+00, 1.6595e-06, 9.7746e-07, 7.3632e-07, 1.0000e+00],\n",
      "        [1.0000e+00, 1.8216e-06, 1.0795e-06, 8.1954e-07, 1.0000e+00],\n",
      "        [1.0000e+00, 1.6610e-06, 9.7814e-07, 7.3757e-07, 1.0000e+00],\n",
      "        [1.0000e+00, 2.1884e-06, 1.3091e-06, 1.0053e-06, 1.0000e+00],\n",
      "        [1.0000e+00, 1.6810e-06, 9.9174e-07, 7.4673e-07, 1.0000e+00],\n",
      "        [1.0000e+00, 1.6530e-06, 9.7341e-07, 7.3256e-07, 1.0000e+00],\n",
      "        [1.0000e+00, 2.5406e-06, 1.5348e-06, 1.1883e-06, 1.0000e+00],\n",
      "        [1.0000e+00, 1.6405e-06, 9.6598e-07, 7.2531e-07, 1.0000e+00],\n",
      "        [1.0000e+00, 1.6532e-06, 9.7348e-07, 7.3302e-07, 1.0000e+00],\n",
      "        [9.9997e-01, 7.6803e-05, 5.2418e-05, 4.6281e-05, 9.9987e-01],\n",
      "        [1.0000e+00, 1.6839e-06, 9.9291e-07, 7.4853e-07, 1.0000e+00],\n",
      "        [1.0000e+00, 1.6307e-06, 9.5935e-07, 7.2115e-07, 1.0000e+00],\n",
      "        [1.0000e+00, 1.6502e-06, 9.7174e-07, 7.3099e-07, 1.0000e+00]],\n",
      "       grad_fn=<SigmoidBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3it [00:00,  5.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.0000e+00, 3.5548e-06, 2.1900e-06, 1.7181e-06, 9.9999e-01],\n",
      "        [1.0000e+00, 1.7035e-06, 1.0053e-06, 7.5924e-07, 1.0000e+00],\n",
      "        [1.0000e+00, 1.6285e-06, 9.5794e-07, 7.1976e-07, 1.0000e+00],\n",
      "        [1.0000e+00, 1.6330e-06, 9.6084e-07, 7.2212e-07, 1.0000e+00],\n",
      "        [1.0000e+00, 1.6648e-06, 9.8092e-07, 7.3890e-07, 1.0000e+00],\n",
      "        [1.0000e+00, 1.6320e-06, 9.6006e-07, 7.2156e-07, 1.0000e+00],\n",
      "        [1.0000e+00, 4.4092e-06, 2.7533e-06, 2.1727e-06, 9.9999e-01],\n",
      "        [1.0000e+00, 1.7115e-06, 1.0102e-06, 7.6335e-07, 1.0000e+00],\n",
      "        [1.0000e+00, 1.6280e-06, 9.5745e-07, 7.1960e-07, 1.0000e+00],\n",
      "        [1.0000e+00, 1.7734e-06, 1.0494e-06, 7.9420e-07, 1.0000e+00],\n",
      "        [1.0000e+00, 2.1897e-06, 1.3126e-06, 1.0117e-06, 1.0000e+00],\n",
      "        [1.0000e+00, 1.6576e-06, 9.7628e-07, 7.3546e-07, 1.0000e+00],\n",
      "        [1.0000e+00, 1.0580e-05, 6.6691e-06, 5.4811e-06, 9.9998e-01],\n",
      "        [1.0000e+00, 1.6313e-06, 9.5936e-07, 7.2150e-07, 1.0000e+00],\n",
      "        [9.9999e-01, 2.9620e-05, 1.9408e-05, 1.6547e-05, 9.9995e-01],\n",
      "        [1.0000e+00, 1.6269e-06, 9.5695e-07, 7.1886e-07, 1.0000e+00],\n",
      "        [1.0000e+00, 1.6420e-06, 9.6615e-07, 7.2709e-07, 1.0000e+00],\n",
      "        [1.0000e+00, 1.6222e-06, 9.5405e-07, 7.1605e-07, 1.0000e+00],\n",
      "        [1.0000e+00, 1.6261e-06, 9.5641e-07, 7.1739e-07, 1.0000e+00],\n",
      "        [9.9996e-01, 8.3359e-05, 5.9957e-05, 5.1650e-05, 9.9986e-01],\n",
      "        [1.0000e+00, 3.5242e-06, 2.1738e-06, 1.6978e-06, 9.9999e-01],\n",
      "        [1.0000e+00, 1.6995e-06, 1.0027e-06, 7.5689e-07, 1.0000e+00],\n",
      "        [1.0000e+00, 1.6265e-06, 9.5652e-07, 7.1886e-07, 1.0000e+00],\n",
      "        [1.0000e+00, 1.7686e-06, 1.0459e-06, 7.9195e-07, 1.0000e+00],\n",
      "        [1.0000e+00, 1.6413e-06, 9.6559e-07, 7.2706e-07, 1.0000e+00],\n",
      "        [9.9968e-01, 6.3255e-04, 4.6951e-04, 4.4009e-04, 9.9904e-01],\n",
      "        [1.0000e+00, 1.6365e-06, 9.6317e-07, 7.2409e-07, 1.0000e+00],\n",
      "        [1.0000e+00, 8.2646e-06, 5.1469e-06, 4.1863e-06, 9.9999e-01],\n",
      "        [1.0000e+00, 1.7060e-06, 1.0071e-06, 7.6016e-07, 1.0000e+00],\n",
      "        [1.0000e+00, 2.0995e-06, 1.2538e-06, 9.6083e-07, 1.0000e+00],\n",
      "        [1.0000e+00, 2.1359e-06, 1.2748e-06, 9.7892e-07, 1.0000e+00],\n",
      "        [9.9997e-01, 6.4577e-05, 4.3702e-05, 3.8308e-05, 9.9990e-01]],\n",
      "       grad_fn=<SigmoidBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5it [00:00,  5.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.0000e+00, 1.6218e-06, 9.5399e-07, 7.1585e-07, 1.0000e+00],\n",
      "        [1.0000e+00, 1.7662e-06, 1.0446e-06, 7.9065e-07, 1.0000e+00],\n",
      "        [1.0000e+00, 1.6347e-06, 9.6162e-07, 7.2318e-07, 1.0000e+00],\n",
      "        [1.0000e+00, 1.7010e-06, 1.0035e-06, 7.5856e-07, 1.0000e+00],\n",
      "        [1.0000e+00, 1.6229e-06, 9.5422e-07, 7.1692e-07, 1.0000e+00],\n",
      "        [1.0000e+00, 1.7306e-06, 1.0225e-06, 7.7341e-07, 1.0000e+00],\n",
      "        [1.0000e+00, 2.2251e-06, 1.3331e-06, 1.0252e-06, 1.0000e+00],\n",
      "        [1.0000e+00, 1.7196e-06, 1.0145e-06, 7.6631e-07, 1.0000e+00],\n",
      "        [1.0000e+00, 1.6299e-06, 9.5902e-07, 7.2027e-07, 1.0000e+00],\n",
      "        [1.0000e+00, 1.7605e-06, 1.0414e-06, 7.9003e-07, 1.0000e+00],\n",
      "        [1.0000e+00, 1.8045e-06, 1.0682e-06, 8.1197e-07, 1.0000e+00],\n",
      "        [1.0000e+00, 1.6118e-06, 9.4782e-07, 7.1018e-07, 1.0000e+00],\n",
      "        [1.0000e+00, 2.2234e-06, 1.3303e-06, 1.0239e-06, 1.0000e+00],\n",
      "        [1.0000e+00, 1.6302e-06, 9.5869e-07, 7.2110e-07, 1.0000e+00],\n",
      "        [1.0000e+00, 1.6442e-06, 9.6761e-07, 7.2814e-07, 1.0000e+00],\n",
      "        [1.0000e+00, 1.6608e-06, 9.7827e-07, 7.3638e-07, 1.0000e+00],\n",
      "        [1.0000e+00, 1.7835e-06, 1.0519e-06, 7.9659e-07, 1.0000e+00],\n",
      "        [1.0000e+00, 1.6333e-06, 9.6086e-07, 7.2245e-07, 1.0000e+00],\n",
      "        [1.0000e+00, 1.6273e-06, 9.5708e-07, 7.1797e-07, 1.0000e+00],\n",
      "        [1.0000e+00, 1.6232e-06, 9.5476e-07, 7.1675e-07, 1.0000e+00],\n",
      "        [1.0000e+00, 1.6453e-06, 9.6822e-07, 7.2896e-07, 1.0000e+00],\n",
      "        [1.0000e+00, 2.0447e-06, 1.2164e-06, 9.3278e-07, 1.0000e+00],\n",
      "        [1.0000e+00, 1.7620e-06, 1.0417e-06, 7.8866e-07, 1.0000e+00],\n",
      "        [1.0000e+00, 1.7055e-06, 1.0058e-06, 7.6140e-07, 1.0000e+00],\n",
      "        [1.0000e+00, 1.6442e-06, 9.6804e-07, 7.2685e-07, 1.0000e+00],\n",
      "        [1.0000e+00, 1.6523e-06, 9.7314e-07, 7.3213e-07, 1.0000e+00],\n",
      "        [1.0000e+00, 2.1737e-06, 1.2990e-06, 9.9925e-07, 1.0000e+00],\n",
      "        [1.0000e+00, 8.0390e-06, 5.0091e-06, 4.0689e-06, 9.9999e-01],\n",
      "        [1.0000e+00, 1.6274e-06, 9.5710e-07, 7.1913e-07, 1.0000e+00],\n",
      "        [9.9997e-01, 7.6656e-05, 5.2219e-05, 4.5995e-05, 9.9988e-01],\n",
      "        [1.0000e+00, 1.7356e-06, 1.0252e-06, 7.7482e-07, 1.0000e+00],\n",
      "        [1.0000e+00, 1.6256e-06, 9.5608e-07, 7.1815e-07, 1.0000e+00]],\n",
      "       grad_fn=<SigmoidBackward0>)\n",
      "tensor([[1.0000e+00, 2.0889e-06, 1.2487e-06, 9.5906e-07, 1.0000e+00],\n",
      "        [1.0000e+00, 1.8430e-06, 1.0928e-06, 8.3128e-07, 1.0000e+00],\n",
      "        [1.0000e+00, 1.9835e-06, 1.1785e-06, 8.9959e-07, 1.0000e+00],\n",
      "        [1.0000e+00, 1.6624e-06, 9.7877e-07, 7.3576e-07, 1.0000e+00],\n",
      "        [1.0000e+00, 1.6752e-06, 9.8719e-07, 7.4513e-07, 1.0000e+00],\n",
      "        [1.0000e+00, 1.9166e-06, 1.1357e-06, 8.6517e-07, 1.0000e+00],\n",
      "        [1.0000e+00, 1.6797e-06, 9.8894e-07, 7.4553e-07, 1.0000e+00],\n",
      "        [1.0000e+00, 1.6458e-06, 9.6851e-07, 7.2961e-07, 1.0000e+00],\n",
      "        [1.0000e+00, 1.6169e-06, 9.5091e-07, 7.1272e-07, 1.0000e+00],\n",
      "        [1.0000e+00, 2.2026e-06, 1.3185e-06, 1.0138e-06, 1.0000e+00],\n",
      "        [1.0000e+00, 2.1211e-06, 1.2659e-06, 9.7081e-07, 1.0000e+00],\n",
      "        [9.9996e-01, 8.3359e-05, 5.9957e-05, 5.1650e-05, 9.9986e-01],\n",
      "        [1.0000e+00, 1.6577e-06, 9.7682e-07, 7.3454e-07, 1.0000e+00],\n",
      "        [9.9999e-01, 1.4954e-05, 9.5715e-06, 7.9849e-06, 9.9997e-01]],\n",
      "       grad_fn=<SigmoidBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "for j, data in tqdm(enumerate(test_loader)):\n",
    "    features, targets = data['features'], data['targets']\n",
    "    pred = model(features)\n",
    "    print(pred)\n",
    "    \n",
    "    fin_targets.extend(targets.cpu().detach().numpy().tolist())\n",
    "    fin_outputs.extend((np.array(pred.cpu().detach().numpy()) >= .3).tolist())\n",
    "\n",
    "    cpu_y = np.where(\n",
    "        fin_targets == False,\n",
    "        0,\n",
    "        np.where(fin_targets == True, 1, np.array(fin_targets)),\n",
    "    )\n",
    "    cpu_y_hat = np.where(\n",
    "        fin_targets == False,\n",
    "        0,\n",
    "        np.where(fin_targets == True, 1, np.array(fin_outputs)),\n",
    "    )\n",
    "    cpu_y = cpu_y.reshape(cpu_y_hat.shape)\n",
    "    results = {}\n",
    "    f_score_tot_none = f1_score(cpu_y, cpu_y_hat, average=None)\n",
    "    f_score_tot_micro = f1_score(cpu_y, cpu_y_hat, average=\"micro\")\n",
    "    f_score_tot_macro = f1_score(cpu_y, cpu_y_hat, average=\"macro\")\n",
    "    f_score_tot_weighted = f1_score(cpu_y, cpu_y_hat, average=\"weighted\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_on_val():\n",
    "    model.eval()\n",
    "    tot_loss=0.0\n",
    "    for i, batch in enumerate(val_loader):\n",
    "        features, targets = batch['features'], batch['targets']\n",
    "        with torch.no_grad():\n",
    "            pred = model(features)\n",
    "        loss = criterion(pred, targets)\n",
    "        tot_loss += loss / pred.shape[0]\n",
    "    return loss\n",
    "\n",
    "hist_train_loss = []\n",
    "hist_test_loss = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0026, 0.0038, 0.0025, 0.0037, 0.0021],\n",
       "        [0.0026, 0.0038, 0.0025, 0.0037, 0.0021],\n",
       "        [0.0026, 0.0038, 0.0025, 0.0037, 0.0021],\n",
       "        [0.0026, 0.0038, 0.0025, 0.0037, 0.0021],\n",
       "        [0.0026, 0.0038, 0.0025, 0.0037, 0.0021],\n",
       "        [0.0026, 0.0038, 0.0025, 0.0037, 0.0021],\n",
       "        [0.0026, 0.0038, 0.0025, 0.0037, 0.0021],\n",
       "        [0.0026, 0.0038, 0.0025, 0.0037, 0.0021],\n",
       "        [0.0026, 0.0038, 0.0025, 0.0037, 0.0021],\n",
       "        [0.0026, 0.0038, 0.0025, 0.0037, 0.0021],\n",
       "        [0.0026, 0.0038, 0.0025, 0.0037, 0.0021],\n",
       "        [0.0026, 0.0038, 0.0025, 0.0037, 0.0021],\n",
       "        [0.0026, 0.0038, 0.0025, 0.0037, 0.0021],\n",
       "        [0.0026, 0.0038, 0.0025, 0.0037, 0.0021],\n",
       "        [0.0026, 0.0038, 0.0025, 0.0037, 0.0021],\n",
       "        [0.0026, 0.0038, 0.0025, 0.0037, 0.0021],\n",
       "        [0.0026, 0.0038, 0.0025, 0.0037, 0.0021],\n",
       "        [0.0026, 0.0038, 0.0025, 0.0037, 0.0021],\n",
       "        [0.0026, 0.0038, 0.0025, 0.0037, 0.0021],\n",
       "        [0.0026, 0.0038, 0.0025, 0.0037, 0.0021],\n",
       "        [0.0026, 0.0038, 0.0025, 0.0037, 0.0021],\n",
       "        [0.0026, 0.0038, 0.0025, 0.0037, 0.0021],\n",
       "        [0.0026, 0.0038, 0.0025, 0.0037, 0.0021],\n",
       "        [0.0026, 0.0038, 0.0025, 0.0037, 0.0021],\n",
       "        [0.0026, 0.0038, 0.0025, 0.0037, 0.0021],\n",
       "        [0.0026, 0.0038, 0.0025, 0.0037, 0.0021],\n",
       "        [0.0026, 0.0038, 0.0025, 0.0037, 0.0021],\n",
       "        [0.0026, 0.0038, 0.0025, 0.0037, 0.0021],\n",
       "        [0.0026, 0.0038, 0.0025, 0.0037, 0.0021],\n",
       "        [0.0026, 0.0038, 0.0025, 0.0037, 0.0021],\n",
       "        [0.0026, 0.0038, 0.0025, 0.0037, 0.0021],\n",
       "        [0.0026, 0.0038, 0.0025, 0.0037, 0.0021],\n",
       "        [0.0026, 0.0038, 0.0025, 0.0037, 0.0021],\n",
       "        [0.0026, 0.0038, 0.0025, 0.0037, 0.0021],\n",
       "        [0.0026, 0.0038, 0.0025, 0.0037, 0.0021],\n",
       "        [0.0026, 0.0038, 0.0025, 0.0037, 0.0021],\n",
       "        [0.0026, 0.0038, 0.0025, 0.0037, 0.0021],\n",
       "        [0.0026, 0.0038, 0.0025, 0.0037, 0.0021],\n",
       "        [0.0026, 0.0038, 0.0025, 0.0037, 0.0021],\n",
       "        [0.0026, 0.0038, 0.0025, 0.0037, 0.0021],\n",
       "        [0.0026, 0.0038, 0.0025, 0.0037, 0.0021],\n",
       "        [0.0026, 0.0038, 0.0025, 0.0037, 0.0021],\n",
       "        [0.0026, 0.0038, 0.0025, 0.0037, 0.0021],\n",
       "        [0.0026, 0.0038, 0.0025, 0.0037, 0.0021],\n",
       "        [0.0026, 0.0038, 0.0025, 0.0037, 0.0021],\n",
       "        [0.0026, 0.0038, 0.0025, 0.0037, 0.0021],\n",
       "        [0.0026, 0.0038, 0.0025, 0.0037, 0.0021],\n",
       "        [0.0026, 0.0038, 0.0025, 0.0037, 0.0021],\n",
       "        [0.0026, 0.0038, 0.0025, 0.0037, 0.0021],\n",
       "        [0.0026, 0.0038, 0.0025, 0.0037, 0.0021],\n",
       "        [0.0026, 0.0038, 0.0025, 0.0037, 0.0021],\n",
       "        [0.0026, 0.0038, 0.0025, 0.0037, 0.0021],\n",
       "        [0.0026, 0.0038, 0.0025, 0.0037, 0.0021],\n",
       "        [0.0026, 0.0038, 0.0025, 0.0037, 0.0021],\n",
       "        [0.0026, 0.0038, 0.0025, 0.0037, 0.0021],\n",
       "        [0.0026, 0.0038, 0.0025, 0.0037, 0.0021],\n",
       "        [0.0026, 0.0038, 0.0025, 0.0037, 0.0021],\n",
       "        [0.0026, 0.0038, 0.0025, 0.0037, 0.0021],\n",
       "        [0.0026, 0.0038, 0.0025, 0.0037, 0.0021],\n",
       "        [0.0026, 0.0038, 0.0025, 0.0037, 0.0021],\n",
       "        [0.0032, 0.0045, 0.0030, 0.0043, 0.0025],\n",
       "        [0.0026, 0.0038, 0.0025, 0.0037, 0.0021],\n",
       "        [0.0031, 0.0045, 0.0030, 0.0043, 0.0025],\n",
       "        [0.0026, 0.0038, 0.0025, 0.0037, 0.0021],\n",
       "        [0.0026, 0.0038, 0.0025, 0.0037, 0.0021],\n",
       "        [0.0026, 0.0038, 0.0025, 0.0037, 0.0021],\n",
       "        [0.0026, 0.0038, 0.0025, 0.0037, 0.0021],\n",
       "        [0.0026, 0.0038, 0.0025, 0.0037, 0.0021],\n",
       "        [0.0026, 0.0038, 0.0025, 0.0037, 0.0021],\n",
       "        [0.0026, 0.0038, 0.0025, 0.0037, 0.0021],\n",
       "        [0.0026, 0.0038, 0.0025, 0.0037, 0.0021],\n",
       "        [0.0026, 0.0038, 0.0025, 0.0037, 0.0021],\n",
       "        [0.0026, 0.0038, 0.0025, 0.0037, 0.0021],\n",
       "        [0.0026, 0.0038, 0.0025, 0.0037, 0.0021],\n",
       "        [0.0034, 0.0047, 0.0032, 0.0046, 0.0026],\n",
       "        [0.0026, 0.0038, 0.0025, 0.0037, 0.0021],\n",
       "        [0.0026, 0.0038, 0.0025, 0.0037, 0.0021],\n",
       "        [0.0026, 0.0038, 0.0025, 0.0037, 0.0021],\n",
       "        [0.0026, 0.0038, 0.0025, 0.0037, 0.0021],\n",
       "        [0.0026, 0.0038, 0.0025, 0.0037, 0.0021],\n",
       "        [0.0026, 0.0038, 0.0025, 0.0037, 0.0021],\n",
       "        [0.0026, 0.0038, 0.0025, 0.0037, 0.0021],\n",
       "        [0.0032, 0.0045, 0.0030, 0.0044, 0.0025],\n",
       "        [0.0026, 0.0038, 0.0025, 0.0037, 0.0021],\n",
       "        [0.0026, 0.0038, 0.0025, 0.0037, 0.0021],\n",
       "        [0.0026, 0.0038, 0.0025, 0.0037, 0.0021],\n",
       "        [0.0026, 0.0038, 0.0025, 0.0037, 0.0021],\n",
       "        [0.0032, 0.0045, 0.0030, 0.0044, 0.0025],\n",
       "        [0.0026, 0.0038, 0.0025, 0.0037, 0.0021],\n",
       "        [0.0026, 0.0038, 0.0025, 0.0037, 0.0021],\n",
       "        [0.0026, 0.0038, 0.0025, 0.0037, 0.0021],\n",
       "        [0.0026, 0.0038, 0.0025, 0.0037, 0.0021],\n",
       "        [0.0032, 0.0045, 0.0030, 0.0044, 0.0025],\n",
       "        [0.0026, 0.0038, 0.0025, 0.0037, 0.0021],\n",
       "        [0.0026, 0.0038, 0.0025, 0.0037, 0.0021],\n",
       "        [0.0026, 0.0038, 0.0025, 0.0037, 0.0021],\n",
       "        [0.0026, 0.0038, 0.0025, 0.0037, 0.0021],\n",
       "        [0.0026, 0.0038, 0.0025, 0.0038, 0.0021],\n",
       "        [0.0026, 0.0038, 0.0025, 0.0037, 0.0021],\n",
       "        [0.0026, 0.0038, 0.0025, 0.0037, 0.0021],\n",
       "        [0.0026, 0.0038, 0.0025, 0.0038, 0.0021],\n",
       "        [0.0026, 0.0038, 0.0025, 0.0037, 0.0021],\n",
       "        [0.0026, 0.0038, 0.0025, 0.0037, 0.0021],\n",
       "        [0.0026, 0.0038, 0.0025, 0.0037, 0.0021],\n",
       "        [0.0026, 0.0038, 0.0025, 0.0037, 0.0021],\n",
       "        [0.0026, 0.0038, 0.0025, 0.0037, 0.0021],\n",
       "        [0.0026, 0.0038, 0.0025, 0.0037, 0.0021],\n",
       "        [0.0026, 0.0038, 0.0025, 0.0037, 0.0021],\n",
       "        [0.0026, 0.0038, 0.0025, 0.0037, 0.0021],\n",
       "        [0.0026, 0.0038, 0.0025, 0.0037, 0.0021],\n",
       "        [0.0026, 0.0038, 0.0025, 0.0037, 0.0021],\n",
       "        [0.0026, 0.0038, 0.0025, 0.0037, 0.0021],\n",
       "        [0.0026, 0.0038, 0.0025, 0.0037, 0.0021],\n",
       "        [0.0026, 0.0038, 0.0025, 0.0037, 0.0021],\n",
       "        [0.0026, 0.0038, 0.0025, 0.0037, 0.0021],\n",
       "        [0.0026, 0.0038, 0.0025, 0.0037, 0.0021],\n",
       "        [0.0026, 0.0038, 0.0025, 0.0037, 0.0021],\n",
       "        [0.0026, 0.0038, 0.0025, 0.0037, 0.0021],\n",
       "        [0.0026, 0.0038, 0.0025, 0.0037, 0.0021],\n",
       "        [0.0026, 0.0038, 0.0025, 0.0037, 0.0021],\n",
       "        [0.0026, 0.0038, 0.0025, 0.0037, 0.0021],\n",
       "        [0.0026, 0.0038, 0.0025, 0.0037, 0.0021],\n",
       "        [0.0026, 0.0038, 0.0025, 0.0037, 0.0021],\n",
       "        [0.0026, 0.0038, 0.0025, 0.0037, 0.0021],\n",
       "        [0.0026, 0.0038, 0.0025, 0.0038, 0.0021],\n",
       "        [0.0026, 0.0038, 0.0025, 0.0037, 0.0021],\n",
       "        [0.0026, 0.0038, 0.0025, 0.0037, 0.0021],\n",
       "        [0.0026, 0.0038, 0.0025, 0.0037, 0.0021],\n",
       "        [0.0026, 0.0038, 0.0025, 0.0037, 0.0021],\n",
       "        [0.0026, 0.0038, 0.0025, 0.0037, 0.0021],\n",
       "        [0.0026, 0.0038, 0.0025, 0.0037, 0.0021],\n",
       "        [0.0026, 0.0038, 0.0025, 0.0037, 0.0021],\n",
       "        [0.0026, 0.0038, 0.0025, 0.0037, 0.0021],\n",
       "        [0.0026, 0.0038, 0.0025, 0.0037, 0.0021],\n",
       "        [0.0026, 0.0038, 0.0025, 0.0037, 0.0021],\n",
       "        [0.0026, 0.0038, 0.0025, 0.0037, 0.0021],\n",
       "        [0.0026, 0.0038, 0.0025, 0.0037, 0.0021],\n",
       "        [0.0033, 0.0047, 0.0031, 0.0045, 0.0026],\n",
       "        [0.0026, 0.0038, 0.0025, 0.0037, 0.0021],\n",
       "        [0.0026, 0.0038, 0.0025, 0.0037, 0.0021],\n",
       "        [0.0026, 0.0038, 0.0025, 0.0037, 0.0021],\n",
       "        [0.0026, 0.0038, 0.0025, 0.0037, 0.0021],\n",
       "        [0.0026, 0.0038, 0.0025, 0.0037, 0.0021],\n",
       "        [0.0034, 0.0048, 0.0032, 0.0046, 0.0026]], grad_fn=<SigmoidBackward0>)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test = dataset.get_test()\n",
    "pred = model(y_test['features'])\n",
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "crit = torch.nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(8.7916)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "crit(y_test['targets'], torch.square(torch.randn(pred.shape)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 0., 0., 0., 0.],\n",
       "        [1., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0.],\n",
       "        [1., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 1.],\n",
       "        [0., 0., 0., 1., 0.],\n",
       "        [1., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 1.],\n",
       "        [0., 1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 1.],\n",
       "        [1., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 1.],\n",
       "        [1., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0.],\n",
       "        [0., 1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0., 0.],\n",
       "        [0., 1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0., 0.],\n",
       "        [1., 0., 0., 0., 0.],\n",
       "        [1., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 1.],\n",
       "        [1., 0., 1., 0., 0.],\n",
       "        [1., 0., 0., 0., 0.],\n",
       "        [1., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 1.],\n",
       "        [1., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 1.],\n",
       "        [0., 0., 0., 0., 1.],\n",
       "        [0., 0., 0., 0., 0.],\n",
       "        [1., 0., 0., 0., 0.],\n",
       "        [1., 0., 0., 0., 0.],\n",
       "        [1., 0., 0., 0., 1.],\n",
       "        [1., 0., 0., 0., 0.],\n",
       "        [1., 0., 0., 0., 0.],\n",
       "        [1., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 1.],\n",
       "        [0., 0., 0., 0., 1.],\n",
       "        [0., 0., 0., 0., 1.],\n",
       "        [1., 0., 0., 0., 1.],\n",
       "        [1., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 1.],\n",
       "        [0., 0., 0., 1., 0.],\n",
       "        [0., 0., 0., 0., 1.],\n",
       "        [0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 1.],\n",
       "        [0., 0., 0., 0., 1.],\n",
       "        [0., 1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 1.],\n",
       "        [0., 0., 0., 0., 1.],\n",
       "        [0., 0., 0., 0., 1.],\n",
       "        [0., 0., 0., 0., 1.],\n",
       "        [1., 0., 0., 0., 0.],\n",
       "        [1., 0., 0., 0., 0.],\n",
       "        [1., 0., 0., 0., 0.],\n",
       "        [1., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 1.],\n",
       "        [0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0.],\n",
       "        [1., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0.],\n",
       "        [1., 0., 0., 0., 0.],\n",
       "        [1., 0., 0., 0., 0.],\n",
       "        [1., 0., 0., 0., 0.],\n",
       "        [1., 0., 0., 0., 0.],\n",
       "        [1., 0., 0., 0., 0.],\n",
       "        [1., 0., 0., 0., 0.],\n",
       "        [0., 1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 1.],\n",
       "        [0., 0., 0., 0., 1.],\n",
       "        [0., 0., 0., 0., 1.],\n",
       "        [0., 0., 1., 0., 0.],\n",
       "        [0., 1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0., 0.],\n",
       "        [1., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 1., 0.],\n",
       "        [1., 0., 0., 0., 0.],\n",
       "        [1., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0.],\n",
       "        [0., 1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0., 0.],\n",
       "        [0., 1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0., 0.],\n",
       "        [1., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 1.],\n",
       "        [0., 0., 0., 0., 1.],\n",
       "        [0., 0., 0., 0., 1.],\n",
       "        [0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 1.],\n",
       "        [0., 0., 0., 0., 1.],\n",
       "        [0., 0., 0., 0., 1.],\n",
       "        [0., 0., 0., 0., 1.],\n",
       "        [1., 0., 0., 0., 0.],\n",
       "        [1., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 1.],\n",
       "        [0., 0., 1., 0., 0.],\n",
       "        [0., 0., 0., 0., 1.],\n",
       "        [0., 0., 0., 0., 1.],\n",
       "        [1., 0., 0., 0., 0.],\n",
       "        [0., 1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0., 0.],\n",
       "        [1., 0., 0., 0., 0.],\n",
       "        [1., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0.],\n",
       "        [0., 1., 0., 0., 0.],\n",
       "        [0., 1., 0., 0., 1.],\n",
       "        [0., 0., 0., 0., 1.],\n",
       "        [0., 0., 0., 0., 1.],\n",
       "        [0., 0., 0., 0., 1.],\n",
       "        [0., 0., 0., 1., 0.],\n",
       "        [0., 0., 0., 0., 1.],\n",
       "        [0., 0., 0., 0., 0.],\n",
       "        [0., 0., 1., 0., 1.],\n",
       "        [1., 0., 0., 0., 1.],\n",
       "        [0., 0., 1., 0., 0.],\n",
       "        [1., 0., 0., 0., 0.],\n",
       "        [1., 0., 0., 0., 0.],\n",
       "        [0., 1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0., 0.],\n",
       "        [1., 0., 0., 0., 0.],\n",
       "        [1., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 1., 0.],\n",
       "        [0., 0., 0., 0., 1.],\n",
       "        [0., 0., 0., 0., 1.],\n",
       "        [0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 1.],\n",
       "        [0., 0., 0., 0., 1.],\n",
       "        [0., 0., 0., 0., 1.],\n",
       "        [0., 0., 0., 1., 0.],\n",
       "        [0., 0., 0., 0., 0.],\n",
       "        [0., 0., 1., 0., 0.],\n",
       "        [0., 0., 0., 0., 1.],\n",
       "        [0., 0., 1., 0., 0.],\n",
       "        [0., 0., 0., 0., 0.],\n",
       "        [0., 0., 1., 0., 0.],\n",
       "        [0., 0., 1., 0., 1.],\n",
       "        [0., 0., 0., 0., 1.],\n",
       "        [0., 0., 1., 0., 0.],\n",
       "        [0., 0., 1., 0., 0.],\n",
       "        [0., 0., 1., 0., 0.],\n",
       "        [0., 0., 0., 0., 1.]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test['targets']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "projet_ewen",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "443553a8d873c13169fd000a429b31bc1f64e807d9cb579432974010f58ecf64"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
