{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/ewenmichel/Desktop/Centrale/3A/SDI/Project/Multimodal-CSC\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "print(os.getcwd())\n",
    "df_source = pd.read_csv(\"data/transcripts/whole_data_2021_2016.csv\")\n",
    "df_source_tot = pd.read_csv(\"data/transcripts/2016_full_behaviors_annotation_w_hedges.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Unnamed: 0', 'Dyad', 'Session', 'P1', 'P2', 'Begin Time - hh:mm:ss.ms',\n",
      "       'End Time - hh:mm:ss.ms', 'Duration - hh:mm:ss.ms'],\n",
      "      dtype='object')\n",
      "11133\n"
     ]
    }
   ],
   "source": [
    "columns = pd.read_csv(\"data/transcripts/clean_D3_S1.csv\").columns\n",
    "df_time = pd.DataFrame(columns = pd.read_csv(\"data/transcripts/clean_D3_S1.csv\").columns)\n",
    "\n",
    "for file in os.listdir(\"./data/transcripts/\"):\n",
    "    if file.startswith(\"clean_\"):\n",
    "        curr_df = pd.read_csv('./data/transcripts/' + file)\n",
    "        if \"Temps de départ - hh:mm:ss.ms\" in curr_df.columns:\n",
    "            curr_df[\"Begin Time - hh:mm:ss.ms\"] = curr_df[\"Temps de départ - hh:mm:ss.ms\"]\n",
    "            curr_df = curr_df.drop(columns = [\"Temps de départ - hh:mm:ss.ms\"])\n",
    "        if 'temps de fin - hh:mm:ss.ms' in curr_df.columns:\n",
    "            curr_df['End Time - hh:mm:ss.ms'] = curr_df['temps de fin - hh:mm:ss.ms']\n",
    "            curr_df = curr_df.drop(columns = ['temps de fin - hh:mm:ss.ms'])\n",
    "        if 'Durée - hh:mm:ss.ms' in curr_df.columns:\n",
    "            curr_df['Duration - hh:mm:ss.ms'] = curr_df['Durée - hh:mm:ss.ms']\n",
    "            curr_df = curr_df.drop(columns = ['Durée - hh:mm:ss.ms'])\n",
    "        df_time = pd.concat([df_time, curr_df])\n",
    "\n",
    "        if '4_S2' in file:\n",
    "            print(curr_df.columns)\n",
    "\n",
    "df_time = df_time.drop(columns = [\"Unnamed: 0\"])\n",
    "df_time = df_time[['Dyad', 'Session', 'Begin Time - hh:mm:ss.ms', 'End Time - hh:mm:ss.ms', 'Duration - hh:mm:ss.ms', 'P1', 'P2']]\n",
    "df_time['Time_begin_ts'] = pd.to_datetime(df_time[\"Begin Time - hh:mm:ss.ms\"], format = \"%H:%M:%S.%f\")\n",
    "\n",
    "print(len(df_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_source[\"Time_begin_ts\"] = pd.to_datetime(df_source[\"Time_begin\"], format = \"%M:%S.%f\")\n",
    "df_time['Time_begin_ts'] = pd.to_datetime(df_time[\"Begin Time - hh:mm:ss.ms\"], format = \"%H:%M:%S.%f\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "print(df_time[\"Time_begin_ts\"].iloc[0] + pd.Timedelta(seconds = 10) < df_time[\"Time_begin_ts\"].iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "738\n",
      "114\n",
      "163\n",
      "2240\n",
      "1368\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([nan, 'x'], dtype=object),\n",
       " array([nan, 'x'], dtype=object),\n",
       " array([nan, 'x'], dtype=object),\n",
       " array([nan, 'x'], dtype=object),\n",
       " array([nan, 'x'], dtype=object))"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df_source = pd.read_csv(\"data/transcripts/whole_data_2021_2016.csv\")\n",
    "df_source = pd.read_csv(\"data/transcripts/2016_full_behaviors_annotation_w_hedges.csv\")\n",
    "for col_ in [\"Time_begin\", \"Time_end\"]:\n",
    "    df_source.loc[:, col_] = df_source.loc[:, col_].apply(lambda x : int(len(str(x)) == len(\"00:01:25\")) * (str(x) + \".000000\") + int(len(str(x)) != 8) * str(x))\n",
    "\n",
    "mask = ((df_source.Dyad == 6) & (df_source.Session == 1))\n",
    "\n",
    "# df_source.loc[mask, [\"P1\", \"P2\"]] = pd.concat([df_source.loc[mask].P2, df_source.loc[mask].P1], axis = 1)\n",
    "df_source.loc[mask, [\"P1\", \"P2\"]] = df_source.loc[mask, [\"P2\", \"P1\"]].values\n",
    "\n",
    "df_source[\"Time_begin_ts\"] = pd.to_datetime(df_source[\"Time_begin\"], format = \"%H:%M:%S.%f\")\n",
    "df_source = df_source.sort_values(by = [\"Dyad\", \"Session\", \"Time_begin\"])\n",
    "\n",
    "sd_df = df_source[(df_source[\"SD_Tutor\"] == \"SD\") | (df_source[\"SD_Tutee\"] == \"SD\")].replace(\"SD\", \"x\").fillna(\"\")\n",
    "qe_df = df_source[(df_source[\"SD_Tutor\"] == \"QE\") | (df_source[\"SD_Tutee\"] == \"QE\")].replace(\"QE\", \"x\").fillna(\"\")\n",
    "sv_df = df_source[(df_source[\"SV_Tutor\"] == \"SV\") | (df_source[\"SV_Tutee\"] == \"SV\")].replace(\"SV\", \"x\").fillna(\"\")\n",
    "pr_df = df_source[(df_source[\"PR_Tutor\"].isin(['LPA', 'UL', 'LPP', 'LPB', '0', 'LP'])) | (df_source[\"PR_Tutee\"].isin(['LPA', 'UL', 'LPP', 'LPB', '0', 'LP']))].replace(['LPA', 'UL', 'LPP', 'LPB', '0', 'LP'], \"x\").fillna(\"\")\n",
    "hd_df = df_source[(df_source[\"HD_Tutor\"].isin(['IDQ/IDS', 'IDQ', 'IDS', 'IDE', 'IDA', 'IDA/IDQ', 'IDQ/IDE', 'IDE/IDS'])) | (df_source[\"HD_Tutee\"].isin(['IDQ/IDS', 'IDQ', 'IDS', 'IDE', 'IDA', 'IDA/IDQ', 'IDQ/IDE', 'IDE/IDS']))].replace(['IDQ/IDS', 'IDQ', 'IDS', 'IDE', 'IDA', 'IDA/IDQ', 'IDQ/IDE', 'IDE/IDS'], \"x\").fillna(\"\")\n",
    "\n",
    "sd_df[\"SD\"] = sd_df.SD_Tutor + sd_df.SD_Tutee\n",
    "qe_df[\"QE\"] = qe_df.SD_Tutor + qe_df.SD_Tutee\n",
    "sv_df[\"SV\"] = sv_df.SV_Tutor + sv_df.SV_Tutee\n",
    "pr_df[\"PR\"] = pr_df.PR_Tutor + pr_df.PR_Tutee\n",
    "hd_df[\"HD\"] = hd_df.HD_Tutor + hd_df.HD_Tutee\n",
    "\n",
    "sd_map_dict = dict(zip(sd_df.index, sd_df[\"SD\"]))\n",
    "qe_map_dict = dict(zip(qe_df.index, qe_df[\"QE\"]))\n",
    "sv_map_dict = dict(zip(sv_df.index, sv_df[\"SV\"]))\n",
    "pr_map_dict = dict(zip(pr_df.index, pr_df[\"PR\"]))\n",
    "hd_map_dict = dict(zip(hd_df.index, hd_df[\"HD\"]))\n",
    "\n",
    "df_source[\"SD\"] = df_source.index.to_series().map(sd_map_dict)\n",
    "df_source[\"QE\"] = df_source.index.to_series().map(qe_map_dict)\n",
    "df_source[\"SV\"] = df_source.index.to_series().map(sv_map_dict)\n",
    "df_source[\"PR\"] = df_source.index.to_series().map(pr_map_dict)\n",
    "df_source[\"HD\"] = df_source.index.to_series().map(hd_map_dict)\n",
    "\n",
    "df_source = df_source.drop(df_source[df_source[\"SV\"] == \"xx\"].index)\n",
    "for l_ in [\"SD\", \"PR\", \"QE\", \"SV\", \"HD\"]:\n",
    "    print(len(df_source[df_source[l_] == 'x']))\n",
    "df_source[\"SD\"].unique(), df_source[\"QE\"].unique(), df_source[\"SV\"].unique(), df_source[\"PR\"].unique(), df_source[\"HD\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13799     the last study I did here took like five minutes\n",
       "13800     and they paid me twenty bucks an hour and a half\n",
       "13801    I didn't really know I was signing up to do ma...\n",
       "13803                                         yeah are you\n",
       "13805                            where do you go to school\n",
       "                               ...                        \n",
       "14554                                              goodbye\n",
       "14556    I'll probably see you at some TechGirls soon-i...\n",
       "14558    I think my mom is forcing me to come on Monday so\n",
       "14559                     pause filler you can hang up now\n",
       "14560                                                 okay\n",
       "Name: P1, Length: 504, dtype: object"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask = (df_source.Dyad == 6) & (df_source.Session == 1) & (df_source.P1.notna())\n",
    "df_source.loc[mask, \"P1\"].iloc[40:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_source = df_source[['Time_begin', 'Dyad', 'Session',  'P1', 'P2', 'SD', 'QE', 'SV', 'PR', 'HD']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_time = df_time[['Dyad', 'Session', 'Begin Time - hh:mm:ss.ms', 'End Time - hh:mm:ss.ms', 'Duration - hh:mm:ss.ms', 'P1', 'P2', 'Time_begin_ts']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'00:00:00.250'"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_time[\"Begin Time - hh:mm:ss.ms\"].iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'00:00:00.100000'"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_source[\"Time_begin\"].iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_result = df_time.merge(df_source, on = ['Dyad', 'Session', 'P1', 'P2'], how = \"left\")\n",
    "df_result = df_result.drop_duplicates().sort_values(by = ['Dyad', 'Session',  'Begin Time - hh:mm:ss.ms'])\n",
    "# df_result = df_result.iloc[:, [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "    # if dyad_ == 11: \n",
    "    #     df_source_fz_ = df_source[(df_source[\"Dyad\"] == dyad_) & (df_source[\"Session\"] == 1)]\n",
    "    #     df_time_fz_ = df_time[(df_time[\"Dyad\"] == dyad_) & (df_time[\"Session\"] == 1)]\n",
    "\n",
    "    #     df_source_fz_ = df_source_fz_[(df_source_fz_[f\"P1\"].notna()) | (df_source_fz_[f\"P2\"].notna())]\n",
    "    #     df_time_fz_ = df_time_fz_[(df_time_fz_[f\"P1\"].notna()) | (df_time_fz_[f\"P2\"].notna())]\n",
    "\n",
    "    #     df_source_fz_[\"P1\"].loc[df_source_fz_[\"P1\"].notna()] = \"1\" + df_source_fz_[\"P1\"]\n",
    "    #     df_source_fz_[\"P2\"].loc[df_source_fz_[\"P2\"].notna()] = \"2\" + df_source_fz_[\"P2\"]\n",
    "\n",
    "    #     df_source_fz_ = df_source_fz_.fillna('')\n",
    "    #     df_source_fz_[\"P\"] = df_source_fz_[\"P1\"] + df_source_fz_[\"P2\"]\n",
    "\n",
    "    #     source_P = df_source_fz_[\"P\"].tolist()\n",
    "    #     source_timestamps = df_source_fz_[\"Time_begin\"] # mm:ss.ms\n",
    "\n",
    "    #     for utt_, ts_ in zip(source_P, source_timestamps):\n",
    "    #         ts_ = pd.to_datetime(ts_, format = \"%M:%S.%f\")\n",
    "    #         curr_df_time_fz_ = df_time_fz_[(df_time_fz_[\"Time_begin_ts\"] < ts_ + pd.Timedelta(seconds=10)) | (df_time_fz_[\"Time_begin_ts\"] > ts_ - pd.Timedelta(seconds=10))]\n",
    "    #         time_P1 = curr_df_time_fz_[\"P1\"].tolist()\n",
    "    #         time_P2 = curr_df_time_fz_[\"P2\"].tolist()\n",
    "    #         if utt_[0] == \"1\":\n",
    "    #             result.append(process.extract(utt_, time_P1, limit = 2))\n",
    "    #         elif utt_[0] == \"2\":\n",
    "    #             result.append(process.extract(utt_, time_P2, limit = 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Applied processor reduces input query to empty string, all comparisons will have score 0. [Query: '']\n",
      "/var/folders/l7/1yhnrkcx2f79z5dph4rg3h540000gn/T/ipykernel_63791/88290716.py:54: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_source_result[\"Match\"] = result\n"
     ]
    }
   ],
   "source": [
    "from fuzzywuzzy import fuzz, process\n",
    "\n",
    "df_source = df_source[(df_source.SD == \"x\") | (df_source.PR == \"x\") | (df_source.HD == \"x\") | (df_source.QE == \"x\") | (df_source.SV == \"x\")]\n",
    "\n",
    "result = []\n",
    "\n",
    "dyad_list = [3,4,5,6,7,8,10]\n",
    "session_list = [1,2]\n",
    "# person_list = [1, 2]\n",
    "threshold = 20\n",
    "\n",
    "df_source = df_source[(df_source[\"P1\"].notna()) ^ (df_source[\"P2\"].notna())]\n",
    "\n",
    "for dyad_ in dyad_list:\n",
    "    for session_ in session_list:\n",
    "        df_source_fz_ = df_source[(df_source[\"Dyad\"] == dyad_) & (df_source[\"Session\"] == session_)]\n",
    "        df_time_fz_ = df_time[(df_time[\"Dyad\"] == dyad_) & (df_time[\"Session\"] == session_)]\n",
    "\n",
    "        df_source_fz_ = df_source_fz_[(df_source_fz_[f\"P1\"].notna()) | (df_source_fz_[f\"P2\"].notna())]\n",
    "        df_time_fz_ = df_time_fz_[(df_time_fz_[f\"P1\"].notna()) | (df_time_fz_[f\"P2\"].notna())]\n",
    "\n",
    "        df_source_fz_.loc[df_source_fz_[\"P1\"].notna(), \"P1\"] = \"1\" + df_source_fz_[\"P1\"]\n",
    "        df_source_fz_.loc[df_source_fz_[\"P2\"].notna(), \"P2\"] = \"2\" + df_source_fz_[\"P2\"]\n",
    "\n",
    "        df_source_fz_ = df_source_fz_.fillna('')\n",
    "        df_source_fz_[\"P\"] = df_source_fz_[\"P1\"] + df_source_fz_[\"P2\"]\n",
    "\n",
    "        source_P = df_source_fz_[\"P\"].tolist()\n",
    "        source_timestamps = df_source_fz_[\"Time_begin\"] # mm:ss.ms\n",
    "\n",
    "        for utt_, ts_ in zip(source_P, source_timestamps):\n",
    "            ts_ = pd.to_datetime(ts_, format = \"%H:%M:%S.%f\")\n",
    "            utt_ = utt_.replace(\"pause filler\", \"\").replace(\"(laughter)\", \"\")\n",
    "            curr_df_time_fz_ = df_time_fz_[(df_time_fz_[\"Time_begin_ts\"] < ts_ + pd.Timedelta(seconds=45)) & (df_time_fz_[\"Time_begin_ts\"] > ts_ - pd.Timedelta(seconds=45))]\n",
    "            time_P1 = curr_df_time_fz_[\"P1\"].apply(lambda x : int(str(x) != \"nan\") * (str(x).strip(\"\\\"\"))).tolist()\n",
    "            time_P2 = curr_df_time_fz_[\"P2\"].apply(lambda x : int(str(x) != \"nan\") * (str(x).strip(\"\\\"\"))).tolist()\n",
    "            if utt_[0] == \"1\":\n",
    "                # if \"I used to play piano\" in time_P1:\n",
    "                #     print(utt_)\n",
    "                #     print(process.extract(utt_[1:], time_P1))\n",
    "                match = process.extract(utt_[1:], time_P1)\n",
    "                if False:\n",
    "                    match = match[0]\n",
    "                result.append(match)\n",
    "            elif utt_[0] == \"2\":\n",
    "                match = process.extract(utt_[1:], time_P2)\n",
    "                if False: # match[0][1]==100\n",
    "                    match = match[0]\n",
    "                result.append(match)\n",
    "\n",
    "            # df_source.loc[((df_source[\"Dyad\"] == dyad_) & (df_source[\"Session\"] == session_) & (df_source[\"P1\"].notna()))]['match'] = result\n",
    "\n",
    "df_source_result = df_source[((df_source[\"P1\"].notna()) ^ (df_source[\"P2\"].notna())) & (df_source[\"Dyad\"].isin(dyad_list)) & (df_source[\"Session\"].isin(session_list))]\n",
    "df_source_result[\"Match\"] = result\n",
    "# df_source_fz = df_source[df_source[\"P1\"].notna()]\n",
    "# df_time_fz = df_source[df_source[\"P1\"].notna()]\n",
    "\n",
    "# source_P1 = df_source_fz[\"P1\"].tolist()\n",
    "# time_P1 = df_time_fz[\"P1\"].tolist()\n",
    "\n",
    "# threshold = 60\n",
    "\n",
    "# result = []\n",
    "\n",
    "# for utt in source_P1:\n",
    "#     result.append(process.extract(utt, time_P1, limit = 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_source_result = df_source_result[[\"Dyad\",\"Session\",\"Time_begin\",\"P1\",\"P2\",\"SD\",\"QE\",\"SV\",\"PR\",\"HD\",\"Match\"]]\n",
    "df_source_result.to_csv(\"fuzzy_test_class_only.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df_fusion = pd.read_csv(\"fuzzy_test_hd.csv\", index_col = [0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of SD in result df : 336\n",
      "Number of SD in source df : 432\n",
      "Number of QE in result df : 78\n",
      "Number of QE in source df : 88\n",
      "Number of PR in result df : 79\n",
      "Number of PR in source df : 63\n",
      "Number of SV in result df : 2089\n",
      "Number of SV in source df : 1342\n",
      "Number of HD in result df : 356\n",
      "Number of HD in source df : 426\n"
     ]
    }
   ],
   "source": [
    "for label in [\"SD\", \"QE\", \"PR\", \"SV\", \"HD\"]:\n",
    "    n_result = len(df_result[(df_result[label] == 'x') & (df_result.Dyad.isin(dyad_list))])\n",
    "    n_source = len(df_source[(df_source[label] == 'x') & (df_source.Dyad.isin(dyad_list))])\n",
    "    print(f\"Number of {label} in result df : {n_result}\")\n",
    "    print(f\"Number of {label} in source df : {n_source}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (721831928.py, line 16)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn [227], line 16\u001b[0;36m\u001b[0m\n\u001b[0;31m    ['ratio', 'token'])``\u001b[0m\n\u001b[0m                       ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "# from fuzzywuzzy import fuzz\n",
    "# from fuzzywuzzy import process\n",
    "\n",
    "# compare_P1 = pd.MultiIndex.from_product([df_source['P1'], df_target['P1']]).to_series()\n",
    "# compare_P2 = pd.MultiIndex.from_product([df_source['P2'], df_target['P2']]).to_series()\n",
    "# compare_D = pd.MultiIndex.from_product([df_source['D'], df_target['D']]).to_series()\n",
    "# compare_S = pd.MultiIndex.from_product([df_source['S'], df_target['S']]).to_series()\n",
    "# compare_S = pd.MultiIndex.from_product([df_source['P1'], df_target['P1']]).to_series()\n",
    "# compare_S = pd.MultiIndex.from_product([df_source['P1'], df_target['P1']]).to_series()\n",
    "\n",
    "# comparisons = [compare_P1, compare_P2, compare_D, compare_S]\n",
    "\n",
    "# def metrics(tup):\n",
    "#     return pd.Series([fuzz.ratio(*tup),\n",
    "#                       fuzz.token_sort_ratio(*tup)],\n",
    "#                      ['ratio', 'token'])``\n",
    "\n",
    "# for comp_ in comparisons:\n",
    "#     comp_.apply(metrics)\n",
    "#     comp_.apply(metrics).unstack().idxmax().unstack(0)\n",
    "#     comp_.apply(metrics).unstack(0).idxmax().unstack(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "a14988f2c8ab5e88cecfa395a5465dfc3038372d0630124ed2d8fb1e7f5e5a63"
  },
  "kernelspec": {
   "display_name": "Python 3.10.0 ('multi-modal-csc')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
